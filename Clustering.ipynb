{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Clustering:\n",
      "+--------------+---------------------------------+---------------------+-------------------------+----------------------+\n",
      "| N (Clusters) |     Preprocessing Technique     |  Silhouette Score   | Calinski-Harabasz Score | Davies-Bouldin Score |\n",
      "+--------------+---------------------------------+---------------------+-------------------------+----------------------+\n",
      "|    N = 3     |        No Preprocessing         | 0.16211078341044485 |    112.5766549221183    |  1.842076807333007   |\n",
      "|              |          Normalization          | 0.32959164656263246 |   286.55469010842927    |  1.3037254268673946  |\n",
      "|              |               PCA               | 0.3350601267863381  |    363.5439327167556    |  1.026234398985492   |\n",
      "|              |    Transform + Normalization    | 0.3430639009542098  |   290.97900516259386    |  0.9775690716294371  |\n",
      "|              | Transform + Normalization + PCA |  0.586342856668023  |    791.5211559479443    |  0.5496171964526538  |\n",
      "|    N = 4     |        No Preprocessing         | 0.14675785172628122 |    95.43011714369715    |  1.9776579865836963  |\n",
      "|              |          Normalization          | 0.23720697525121526 |   245.99994293492512    |  1.5481396442142332  |\n",
      "|              |               PCA               | 0.3419008282193751  |    357.816501777542     |  0.9367173662205814  |\n",
      "|              |    Transform + Normalization    | 0.33529681757969326 |    311.5941271900475    |  0.9794576610920646  |\n",
      "|              | Transform + Normalization + PCA | 0.5659458219352899  |   1325.4005795216483    |  0.5829180126860918  |\n",
      "|    N = 5     |        No Preprocessing         | 0.14111778738848726 |    87.34304567221085    |  1.9271810033679722  |\n",
      "|              |          Normalization          | 0.1958617843761362  |   204.51234554801215    |  1.6859600418844352  |\n",
      "|              |               PCA               | 0.33554813451259047 |   344.86714741499407    |  0.9620127642614941  |\n",
      "|              |    Transform + Normalization    | 0.31824290285248485 |   298.29086664491433    |  0.9209121270173732  |\n",
      "|              | Transform + Normalization + PCA | 0.5452007261666041  |   1296.4769238748038    |  0.577427868176599   |\n",
      "+--------------+---------------------------------+---------------------+-------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "patients = load_diabetes()\n",
    "X = patients.data\n",
    "\n",
    "results_data = []\n",
    "\n",
    "# Different values of N (number of clusters)\n",
    "N_values = [3, 4, 5]\n",
    "\n",
    "for N in N_values:\n",
    "    preprocessing_techniques = {\n",
    "        \"No Preprocessing\": X,\n",
    "        \"Normalization\": MinMaxScaler().fit_transform(X),\n",
    "        \"PCA\": PCA(n_components=2).fit_transform(X),\n",
    "        \"Transform + Normalization\": MinMaxScaler().fit_transform(PCA(n_components=2).fit_transform(X)),\n",
    "        \"Transform + Normalization + PCA\": PCA(n_components=2).fit_transform(MinMaxScaler().fit_transform(X))\n",
    "    }\n",
    "\n",
    "    for technique, data in preprocessing_techniques.items():\n",
    "        # Perform KMeans clustering\n",
    "        clustering = KMeans(n_clusters=N, n_init='auto')\n",
    "        labels = clustering.fit_predict(data)\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        silhouette = silhouette_score(data, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(data, labels)\n",
    "        davies_bouldin = davies_bouldin_score(data, labels)\n",
    "\n",
    "        # Append results to the list, displaying N only once per technique\n",
    "        if technique == \"No Preprocessing\":\n",
    "            results_data.append([\"N = {}\".format(N), technique, silhouette, calinski_harabasz, davies_bouldin])\n",
    "        else:\n",
    "            results_data.append([\"\", technique, silhouette, calinski_harabasz, davies_bouldin])\n",
    "\n",
    "# Table headers\n",
    "headers = [\"N (Clusters)\", \"Preprocessing Technique\", \"Silhouette Score\", \"Calinski-Harabasz Score\", \"Davies-Bouldin Score\"]\n",
    "\n",
    "# Display the table\n",
    "print(\"K-Means Clustering:\")\n",
    "print(tabulate(results_data, headers=headers, tablefmt='pretty'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agglomerative Hierarchical Clustering:\n",
      "+--------------+---------------------------------+---------------------+-------------------------+----------------------+\n",
      "| N (Clusters) |     Preprocessing Technique     |  Silhouette Score   | Calinski-Harabasz Score | Davies-Bouldin Score |\n",
      "+--------------+---------------------------------+---------------------+-------------------------+----------------------+\n",
      "|    N = 3     |        No Preprocessing         | 0.12496473908632375 |    95.75864313388199    |  2.1321806623880435  |\n",
      "|              |          Normalization          | 0.3215407058889175  |    276.313467192541     |  1.3645430219385073  |\n",
      "|              |               PCA               | 0.32326304313858956 |    323.8473474024072    |  1.0960993170328484  |\n",
      "|              |    Transform + Normalization    | 0.31514302808860056 |    284.7483560778795    |  0.9938219629022732  |\n",
      "|              | Transform + Normalization + PCA | 0.6127367955903301  |    957.8771844227998    |  0.5077182695247675  |\n",
      "|    N = 4     |        No Preprocessing         | 0.11304833445801805 |    79.56669479356054    |  2.093684580507442   |\n",
      "|              |          Normalization          | 0.21209542123221226 |   227.42877238130006    |  1.664469058308546   |\n",
      "|              |               PCA               | 0.3294568621199172  |    294.1547090845991    |  0.9098868330661853  |\n",
      "|              |    Transform + Normalization    | 0.30910977956281815 |   265.26110733271656    |  0.9338635356760598  |\n",
      "|              | Transform + Normalization + PCA | 0.5681011666231219  |   1309.3020337606144    |  0.5793377805769285  |\n",
      "|    N = 5     |        No Preprocessing         | 0.1010334170542948  |    71.78880266626574    |  2.0994459499895872  |\n",
      "|              |          Normalization          | 0.14764199500187458 |    184.886377976911     |  1.852325067703331   |\n",
      "|              |               PCA               | 0.29895063710741787 |    301.1118688209504    |  1.0387174139985846  |\n",
      "|              |    Transform + Normalization    | 0.3033981358549366  |    276.6532175503888    |  0.9213117957142588  |\n",
      "|              | Transform + Normalization + PCA | 0.5285654807950902  |   1319.2848977125948    |  0.575199458658907   |\n",
      "+--------------+---------------------------------+---------------------+-------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "patients = load_diabetes()\n",
    "X = patients.data\n",
    "\n",
    "results_data = []\n",
    "\n",
    "# Different values of N (number of clusters)\n",
    "N_values = [3, 4, 5]\n",
    "\n",
    "for N in N_values:\n",
    "    preprocessing_techniques = {\n",
    "        \"No Preprocessing\": X,\n",
    "        \"Normalization\": MinMaxScaler().fit_transform(X),\n",
    "        \"PCA\": PCA(n_components=2).fit_transform(X),\n",
    "        \"Transform + Normalization\": MinMaxScaler().fit_transform(PCA(n_components=2).fit_transform(X)),\n",
    "        \"Transform + Normalization + PCA\": PCA(n_components=2).fit_transform(MinMaxScaler().fit_transform(X))\n",
    "    }\n",
    "\n",
    "    for technique, data in preprocessing_techniques.items():\n",
    "        # Perform Agglomerative Hierarchical Clustering\n",
    "        clustering = AgglomerativeClustering(n_clusters=N)\n",
    "        labels = clustering.fit_predict(data)\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        silhouette = silhouette_score(data, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(data, labels)\n",
    "        davies_bouldin = davies_bouldin_score(data, labels)\n",
    "\n",
    "        # Append results to the list, displaying N only once per technique\n",
    "        if technique == \"No Preprocessing\":\n",
    "            results_data.append([\"N = {}\".format(N), technique, silhouette, calinski_harabasz, davies_bouldin])\n",
    "        else:\n",
    "            results_data.append([\"\", technique, silhouette, calinski_harabasz, davies_bouldin])\n",
    "\n",
    "# Table headers\n",
    "headers = [\"N (Clusters)\", \"Preprocessing Technique\", \"Silhouette Score\", \"Calinski-Harabasz Score\", \"Davies-Bouldin Score\"]\n",
    "\n",
    "# Display the table\n",
    "print(\"Agglomerative Hierarchical Clustering:\")\n",
    "print(tabulate(results_data, headers=headers, tablefmt='pretty'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Clustering:\n",
      "+--------------+---------------------------------+---------------------+-------------------------+----------------------+\n",
      "| N (Clusters) |     Preprocessing Technique     |  Silhouette Score   | Calinski-Harabasz Score | Davies-Bouldin Score |\n",
      "+--------------+---------------------------------+---------------------+-------------------------+----------------------+\n",
      "|    N = 3     |        No Preprocessing         | 0.16998514769554465 |    103.9348596680327    |  1.9967880269977991  |\n",
      "|              |          Normalization          | 0.33059697454392634 |   286.52246817477413    |  1.308370292997756   |\n",
      "|              |               PCA               | 0.3467699661228943  |    300.5302310417969    |  1.1048984477376986  |\n",
      "|              |    Transform + Normalization    | 0.35873528574351016 |   295.81327216961665    |  0.9806970568688942  |\n",
      "|              | Transform + Normalization + PCA | 0.6119680572562323  |    958.4790241732301    |  0.5107102255320352  |\n",
      "|    N = 4     |        No Preprocessing         | 0.13429298118672497 |    86.67183518350716    |  1.9150845642857508  |\n",
      "|              |          Normalization          | 0.22801773334502293 |   242.19783375834942    |  1.5812340754611025  |\n",
      "|              |               PCA               | 0.29330007617074394 |   281.85003951333385    |  0.9954558316267904  |\n",
      "|              |    Transform + Normalization    | 0.30779604565938673 |   257.00085284611527    |  0.9391481283351687  |\n",
      "|              | Transform + Normalization + PCA | 0.5634676305539529  |   1319.3808902122175    |  0.5861636707434215  |\n",
      "|    N = 5     |        No Preprocessing         | 0.13004131716187606 |    74.95233913556427    |  1.8064387822369643  |\n",
      "|              |          Normalization          | 0.19487993977243584 |   203.46601327315915    |  1.6686213660033207  |\n",
      "|              |               PCA               | 0.3065816333973301  |   301.05700955113315    |  0.8922047180387682  |\n",
      "|              |    Transform + Normalization    | 0.29184125305878306 |   253.99376378587334    |  0.8891622399121737  |\n",
      "|              | Transform + Normalization + PCA | 0.5226130491438293  |   1266.0636827099393    |  0.5541744015401949  |\n",
      "+--------------+---------------------------------+---------------------+-------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "patients = load_diabetes()\n",
    "X = patients.data\n",
    "\n",
    "results_data = []\n",
    "\n",
    "# Different values of N (number of clusters)\n",
    "N_values = [3, 4, 5]\n",
    "\n",
    "for N in N_values:\n",
    "    preprocessing_techniques = {\n",
    "        \"No Preprocessing\": X,\n",
    "        \"Normalization\": MinMaxScaler().fit_transform(X),\n",
    "        \"PCA\": PCA(n_components=2).fit_transform(X),\n",
    "        \"Transform + Normalization\": MinMaxScaler().fit_transform(PCA(n_components=2).fit_transform(X)),\n",
    "        \"Transform + Normalization + PCA\": PCA(n_components=2).fit_transform(MinMaxScaler().fit_transform(X))\n",
    "    }\n",
    "\n",
    "    for technique, data in preprocessing_techniques.items():\n",
    "        # Perform Spectral Clustering\n",
    "        clustering = SpectralClustering(n_clusters=N)\n",
    "        labels = clustering.fit_predict(data)\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        silhouette = silhouette_score(data, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(data, labels)\n",
    "        davies_bouldin = davies_bouldin_score(data, labels)\n",
    "\n",
    "        # Append results to the list, displaying N only once per technique\n",
    "        if technique == \"No Preprocessing\":\n",
    "            results_data.append([\"N = {}\".format(N), technique, silhouette, calinski_harabasz, davies_bouldin])\n",
    "        else:\n",
    "            results_data.append([\"\", technique, silhouette, calinski_harabasz, davies_bouldin])\n",
    "\n",
    "# Table headers\n",
    "headers = [\"N (Clusters)\", \"Preprocessing Technique\", \"Silhouette Score\", \"Calinski-Harabasz Score\", \"Davies-Bouldin Score\"]\n",
    "\n",
    "# Display the table\n",
    "print(\"Spectral Clustering:\")\n",
    "print(tabulate(results_data, headers=headers, tablefmt='pretty'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN Clustering:\n",
      "+---------------------------------+---------------------------------+---------------------+-------------------------+----------------------+\n",
      "|           Parameters            |     Preprocessing Technique     |  Silhouette Score   | Calinski-Harabasz Score | Davies-Bouldin Score |\n",
      "+---------------------------------+---------------------------------+---------------------+-------------------------+----------------------+\n",
      "| Epsilon = 0.5, Min Samples = 5  |          Normalization          | 0.39800898088714065 |   205.01166530017693    |  2.360481962946987   |\n",
      "| Epsilon = 0.5, Min Samples = 5  | Transform + Normalization + PCA | 0.6559197265088276  |   1006.5030144117595    |  0.5415783527733922  |\n",
      "| Epsilon = 0.5, Min Samples = 10 |          Normalization          | 0.39800898088714065 |   205.01166530017693    |  2.360481962946987   |\n",
      "| Epsilon = 0.5, Min Samples = 10 | Transform + Normalization + PCA | 0.6559197265088276  |   1006.5030144117595    |  0.5415783527733922  |\n",
      "| Epsilon = 0.5, Min Samples = 15 |          Normalization          | 0.3977720178311146  |    205.4085887737024    |  2.1666639629290576  |\n",
      "| Epsilon = 0.5, Min Samples = 15 | Transform + Normalization + PCA | 0.6559197265088276  |   1006.5030144117595    |  0.5415783527733922  |\n",
      "| Epsilon = 1.0, Min Samples = 5  |          Normalization          | 0.43611432828588426 |    411.7278679032903    |  0.9825658133471726  |\n",
      "| Epsilon = 1.0, Min Samples = 10 |          Normalization          | 0.43611432828588426 |    411.7278679032903    |  0.9825658133471726  |\n",
      "| Epsilon = 1.0, Min Samples = 15 |          Normalization          | 0.43611432828588426 |    411.7278679032903    |  0.9825658133471726  |\n",
      "+---------------------------------+---------------------------------+---------------------+-------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "patients = load_diabetes()\n",
    "X = patients.data\n",
    "\n",
    "results_data = []\n",
    "\n",
    "# Different values of epsilon and minimum samples for DBSCAN\n",
    "epsilon_values = [0.5, 1.0, 1.5]\n",
    "min_samples_values = [5, 10, 15]\n",
    "\n",
    "for epsilon in epsilon_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        for technique in [\"No Preprocessing\", \"Normalization\", \"PCA\", \"Transform + Normalization\", \"Transform + Normalization + PCA\"]:\n",
    "            if technique == \"No Preprocessing\":\n",
    "                data = X\n",
    "            elif technique == \"Normalization\":\n",
    "                data = MinMaxScaler().fit_transform(X)\n",
    "            elif technique == \"PCA\":\n",
    "                data = PCA(n_components=2).fit_transform(X)\n",
    "            elif technique == \"Transform + Normalization\":\n",
    "                data = MinMaxScaler().fit_transform(PCA(n_components=2).fit_transform(X))\n",
    "            elif technique == \"Transform + Normalization + PCA\":\n",
    "                data = PCA(n_components=2).fit_transform(MinMaxScaler().fit_transform(X))\n",
    "            \n",
    "            # Perform DBSCAN Clustering\n",
    "            clustering = DBSCAN(eps=epsilon, min_samples=min_samples)\n",
    "            labels = clustering.fit_predict(data)\n",
    "\n",
    "            # Check if more than one cluster label is generated\n",
    "            if len(np.unique(labels)) > 1:\n",
    "                # Calculate evaluation metrics\n",
    "                silhouette = silhouette_score(data, labels)\n",
    "                calinski_harabasz = calinski_harabasz_score(data, labels)\n",
    "                davies_bouldin = davies_bouldin_score(data, labels)\n",
    "\n",
    "                # Append results to the list\n",
    "                results_data.append([f\"Epsilon = {epsilon}, Min Samples = {min_samples}\", technique, silhouette, calinski_harabasz, davies_bouldin])\n",
    "\n",
    "# Table headers\n",
    "headers = [\"Parameters\", \"Preprocessing Technique\", \"Silhouette Score\", \"Calinski-Harabasz Score\", \"Davies-Bouldin Score\"]\n",
    "\n",
    "# Display the table\n",
    "print(\"DBSCAN Clustering:\")\n",
    "print(tabulate(results_data, headers=headers, tablefmt='pretty'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
